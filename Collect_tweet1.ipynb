{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2afa809d",
   "metadata": {},
   "source": [
    "# Twitter(X)API取得コード"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e5fdc",
   "metadata": {},
   "source": [
    "#### [使い始め時の使い方 for beginner]\n",
    "1. カーネル \".venv(Python 3.12.9) **All_collect_tweet/Forcoltweet/.venv/bin/python**\"を選んでください.\n",
    "2. 【毎度いじるパラメータ】で、\"取得する期間\"と、\"取得するKW\"を設定してください.\n",
    "3. 期間を半日にして、一度取得実験をし、中身が揃っていることを確認してください.\n",
    "4. 大型取得を開始してください.\n",
    "* 取得は、今後のデータ処理のことも考えると、期間設定を1ヶ月ごとに取得してください.\n",
    "\n",
    "#### [参考]\n",
    "* KWが「日経平均」の場合、1ヶ月で約3万-5万ツイート.\n",
    "    * 2025/6/25現在、Pro契約最大100万ツイートまで取得可能. したがって、おおよそ20ヶ月程度取得可能かと思われます.\n",
    "* 100万ツイート取得するのに、本気で画面と向き合えば、10時間で取得完了します.\n",
    "    * 傾向として、取得よりcsv化の方が、処理時間が長い印象です.\n",
    "* 429のエラーが出ているときは、リクエスト制限かかっている可能性があります. 5分程度空けてから実行すると解決するかもしれないです.\n",
    "\n",
    "#### [コード修正をする際の注意点]\n",
    "* APIに取得依頼→csv化してデータ保存の流れです.\n",
    "    * したがって、query_params_base (APIに注文する内容) にあっても row(csvに出力させるときの列) に入れなければ CSV に出力されない です.\n",
    "    * 逆に row 側で入れていても APIで取得してないものは空になります（例: profile_banner_url）.\n",
    "* 本コードは、query_params_baseのほぼ全てを入れているので、row の部分に要素を追加すれば、取得情報を増やせられます. 詳しくはChatGPT等に聞くと正確に返ってくるかと思います.\n",
    "    * context_annotation に関しては、いれると、おそらく動かなくなります. もし仮に使いたい人いれば、MAX_RESULT辺りを小さく(200くらい)してみてください.\n",
    "* 仮想環境に入っているライブラリ一覧を確認したい場合は、同じディレクトリにある pyproject.tomlファイル を参照してください.\n",
    "    * ターミナルを開き、次のコマンド *uv add [ライブラリ名]* で、pip install と同様のインストールができます."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66413e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit remaining: 299 | 目安の日付: 2023-11-01 23:58:43+00:00 | 累計Tweet_count: 379\n",
      "Rate limit remaining: 298 | 目安の日付: 2023-11-01 19:11:22+00:00 | 累計Tweet_count: 765\n",
      "Rate limit remaining: 297 | 目安の日付: 2023-11-01 15:59:09+00:00 | 累計Tweet_count: 1101\n",
      "Rate limit remaining: 296 | 目安の日付: 2023-11-01 14:52:24+00:00 | 累計Tweet_count: 1489\n",
      "Rate limit remaining: 295 | 目安の日付: 2023-11-01 11:45:32+00:00 | 累計Tweet_count: 1865\n",
      "Rate limit remaining: 294 | 目安の日付: 2023-11-01 10:05:26+00:00 | 累計Tweet_count: 2224\n",
      "Rate limit remaining: 293 | 目安の日付: 2023-11-01 08:30:02+00:00 | 累計Tweet_count: 2569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "全情報統合中: 100%|██████████| 2569/2569 [00:00<00:00, 137340.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存しました: /home/sakulab/workspace/All_collect_tweet/collected_tweet/tweets_allinfo_20231101_000000_to_20231101_235959.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# =============================\n",
    "# パラメータ設定\n",
    "# =============================\n",
    "\n",
    "# 【毎度いじるパラメータ】~~~~~~~~~~~~\n",
    "START_TIME = datetime(2023, 11, 1, 0, 0, 0) #取得開始日JST（YYYY-MM-DD HH:MM:SS）\n",
    "END_TIME = datetime(2023, 11, 1, 23, 59, 59) #取得終了日JST（YYYY-MM-DD HH:MM:SS）\n",
    "QUERY = \"日経平均 -is:retweet\" #抽出キーワード\n",
    "'''\n",
    "<QUERY = \"日経平均 -is:retweet\"に関して>\n",
    "日経平均：「日経平均」という文字列を含むツイートを検索\n",
    "-is:retweet:かつ、リツイート（RT）は除外する\n",
    "'''\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "MAX_RESULTS = 500 #安田さん500|1リクエストで取得するツイート数の最大値//10以上でないと動かない.\n",
    "MAX_PAGES = 100000 #安田さん100000|最大で何回リクエストを送るかの上限|参照元の安田さんのコードでは、response_count = 10000として定義していた.\n",
    "'''\n",
    "● MAX_RESULTS = 2、MAX_PAGES = 3 の場合\n",
    "ページ1 → 2件取得  \n",
    "ページ2 → 2件取得  \n",
    "ページ3 → 2件取得  \n",
    "== 合計6件取得\n",
    "--------------------------------------------\n",
    "● MAX_RESULTS = 2、MAX_PAGES = 1 の場合\n",
    "ページ1 → 2件取得   \n",
    "== 合計2件取得\n",
    "'''\n",
    "\n",
    "#.envを使うなら(動作保証なし)\n",
    "load_dotenv(\"/home/sakulab/workspace/All_collect_tweet/Forcoltweet/.env\")\n",
    "BEARER_TOKEN = os.getenv('BEARER_TOKEN')\n",
    "\n",
    "#BEARER_TOKEN = 触らない|ベタ打ち\n",
    "OUTPUT_DIRECTORY = \"/home/sakulab/workspace/All_collect_tweet/collected_tweet\" #csv出力先のファイルパス\n",
    "if not BEARER_TOKEN:\n",
    "    print(\"Warning: BEARER_TOKEN is not set in the .env file\")\n",
    "else:\n",
    "    print(\"BEARER_TOKENは正常に取得されました\")\n",
    "\n",
    "# =============================\n",
    "# 時間変換(JST→UTC)\n",
    "# =============================\n",
    "JST = timedelta(hours=9) # 日本標準時 (JST) は UTC +9時間なので、その9時間を引いてUTCに変換するため.\n",
    "start_time_utc = (START_TIME - JST).isoformat() + \"Z\" # 開始日時をUTCに変換し、ISOフォーマット + Z（ゼロ時区）で文字列化\n",
    "end_time_utc = (END_TIME - JST).isoformat() + \"Z\" # 終了日時を同様にUTC変換・フォーマット\n",
    "\n",
    "# =============================\n",
    "# API設定\n",
    "# =============================\n",
    "url = \"https://api.X.com/2/tweets/search/all\" #proプランでの収集用(本家)\n",
    "#url = \"https://api.X.com/2/tweets/search/recent\"#freeプラン収集用(最大10件程度)\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {BEARER_TOKEN}\"} # リクエストヘッダーに Bearer トークンをセット（認証用）\n",
    "\n",
    "#取得要素の設定\n",
    "query_params_base = {\n",
    "    \"query\": QUERY, # 検索クエリ（キーワード＋条件、例：日経平均 -is:retweet）\n",
    "    \"start_time\": start_time_utc, # 検索開始日時（UTC ISO形式）\n",
    "    \"end_time\": end_time_utc, # 検索終了日時（UTC ISO形式）\n",
    "    \"max_results\": MAX_RESULTS, # 1リクエストあたりの最大取得件数（10～500の範囲）\n",
    "    \"tweet.fields\": \",\".join([ # ツイートから取得したいフィールド一覧\n",
    "        \"attachments\", \"author_id\", \"conversation_id\",#\"context_annotations\",\n",
    "        \"created_at\", \"entities\", \"geo\", \"id\", \"in_reply_to_user_id\", \"lang\",\n",
    "        \"public_metrics\", \"possibly_sensitive\", \"referenced_tweets\",\n",
    "        \"reply_settings\", \"source\", \"text\", \"withheld\"\n",
    "    ]),\n",
    "    \"expansions\": \"author_id,attachments.media_keys,referenced_tweets.id\",  # 結果に含める追加データ（例：ユーザー情報・メディア情報）\n",
    "    \"user.fields\": \",\".join([ # ユーザー情報として取得するフィールド\n",
    "        \"created_at\", \"description\", \"entities\", \"id\", \"location\", \"name\",\n",
    "        \"pinned_tweet_id\", \"profile_image_url\", \"protected\", \"public_metrics\",\n",
    "        \"url\", \"username\", \"verified\", \"withheld\"\n",
    "    ]),\n",
    "    \"media.fields\": \"media_key,type,url,preview_image_url,public_metrics\", # メディア情報で取得するフィールド\n",
    "    \"place.fields\": \"full_name,id,country,country_code,geo,name,place_type\" # 場所情報で取得するフィールド\n",
    "} \n",
    "\n",
    "# =============================\n",
    "# データ収集関数\n",
    "# =============================\n",
    "def collect_tweet(url, headers, base_params):\n",
    "    result = [] # すべてのツイートデータを格納するリスト\n",
    "    tweet_count = 0 #実行中のprint用\n",
    "    all_users = {} # ユーザー情報を author_id をキーに格納する辞書\n",
    "    all_media = {} # メディア情報を media_key をキーに格納する辞書\n",
    "    all_places = {} # 場所情報を place_id をキーに格納する辞書\n",
    "    next_token = None # ページング用のトークン（最初はNone）\n",
    "    count = 0 # リクエスト回数のカウンタ\n",
    "\n",
    "    while count < MAX_PAGES: # 最大リクエスト回数に達するまでループ\n",
    "        time.sleep(1) # APIレート制限対策でリクエスト間に1秒の遅延\n",
    "        params = base_params.copy()# base_params（基本のリクエストパラメータ）をコピーして、新しいparamsを作成\n",
    "        if next_token:\n",
    "            params[\"next_token\"] = next_token # 続きを取得する場合は next_token を指定\n",
    "\n",
    "        response = requests.get(url, headers=headers, params=params) # APIリクエスト送信\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Request failed: {response.status_code}, {response.text}\") # エラー時は例外を発生させ、レスポンス内容を表示|例)status-code=404→ページ見つからない\n",
    "\n",
    "        body = response.json() # JSONレスポンスを辞書化\n",
    "        result.extend(body.get(\"data\", [])) # ツイートデータを結果リストに追加\n",
    "\n",
    "        # 累積件数とレート制限の残りを出力\n",
    "        rate_limit = response.headers.get('x-rate-limit-remaining', 'N/A')\n",
    "        tweet_count += len(body.get(\"data\", []))\n",
    "\n",
    "        if body.get(\"data\"):\n",
    "            created_at_jst = datetime.fromisoformat(body[\"data\"][0][\"created_at\"].replace(\"Z\", \"+00:00\")) + JST\n",
    "            print(f\"Rate limit remaining: {rate_limit} | 目安の日付: {created_at_jst} | 累計Tweet_count: {tweet_count}\")\n",
    "        else:\n",
    "            print(f\"Rate limit remaining: {rate_limit} | データなし | 累計Tweet_count: {tweet_count}\")\n",
    "\n",
    "        # 各種インクルードデータ（ユーザー・メディア・場所情報）を辞書に格納\n",
    "        for user in body.get(\"includes\", {}).get(\"users\", []):\n",
    "            all_users[user[\"id\"]] = user\n",
    "        for media in body.get(\"includes\", {}).get(\"media\", []):\n",
    "            all_media[media[\"media_key\"]] = media\n",
    "        for place in body.get(\"includes\", {}).get(\"places\", []):\n",
    "            all_places[place[\"id\"]] = place\n",
    "\n",
    "        count += 1 # リクエスト回数をインクリメント\n",
    "        next_token = body.get(\"meta\", {}).get(\"next_token\")\n",
    "        if not next_token:\n",
    "            print(\"No more pages to fetch.\")\n",
    "            break # 次トークンが無ければこれ以上のデータはないので終了\n",
    "\n",
    "    return result, all_users, all_media, all_places # 収集した全データを返す\n",
    "\n",
    "# =============================\n",
    "# データ収集実行\n",
    "# =============================\n",
    "#tweets, users_dict, media_dict, places_dict = collect_tweet(url, headers, query_params_base)\n",
    "tweets, users_dict, media_dict, places_dict = collect_tweet(\n",
    "    url,                 # APIエンドポイントのURL (search/all)\n",
    "    headers,             # リクエストの認証ヘッダー (Bearerトークン)\n",
    "    query_params_base    # 検索条件・取得フィールドなどを含むパラメータ\n",
    ")\n",
    "'''\n",
    "# collect_tweet 関数を呼び出して、指定の検索条件でデータ収集を実行\n",
    "# 戻り値は以下の4つ:\n",
    "# tweets: ツイートデータ（リスト形式、ツイート1件ずつが辞書）\n",
    "# users_dict: 投稿者ユーザー情報（ユーザーIDをキー、値がユーザー情報の辞書）\n",
    "# media_dict: 添付メディア情報（media_key をキー、値がメディア情報の辞書）\n",
    "# places_dict: 場所情報（place_id をキー、値が場所情報の辞書）\n",
    "'''\n",
    "\n",
    "# =============================\n",
    "# csv化,データを1行にまとめる\n",
    "# =============================\n",
    "rows = []# rows はツイート＋ユーザー＋メディア＋場所情報を統合したデータを1行ずつ格納するためのリスト.最終的に pandas DataFrame に変換するために使用.\n",
    "\n",
    "for tweet in tqdm(tweets, desc=\"全情報統合中\"):\n",
    "    created_at_jst = (datetime.fromisoformat(tweet[\"created_at\"].replace(\"Z\", \"+00:00\")) + JST) if tweet.get(\"created_at\") else \"\"\n",
    "    # ツイートのcreated_at（UTC:Z=ゼロ時区）をdatetime型に変換し、日本時間 (JST) に変換\n",
    "    # created_at が無ければ空文字\n",
    "\n",
    "    user = users_dict.get(tweet.get(\"author_id\", \"\"), {}) # ツイートの author_id から対応するユーザー情報を取得 / 存在しない場合は空の辞書\n",
    "    user_metrics = user.get(\"public_metrics\", {}) # ユーザーの public_metrics を取得（フォロワー数やツイート数など）/ 無ければ空の辞書\n",
    "    metrics = tweet.get(\"public_metrics\", {}) # ツイートの public_metrics を取得（リツイート数、いいね数など）| 無ければ空の辞書\n",
    "\n",
    "    # メディア情報（複数ある場合は最初のもののみ例として取り出し）\n",
    "    media_info = {} # メディア情報（画像・動画など）を格納する辞書を初期化\n",
    "    media_keys = tweet.get(\"attachments\", {}).get(\"media_keys\", []) # ツイートにメディアが添付されている場合、その media_keys のリストを取得\n",
    "    if media_keys:\n",
    "        media_info = media_dict.get(media_keys[0], {}) # media_keys が存在する場合、最初の media_key に対応するメディア情報を取得\n",
    "\n",
    "    # 場所情報（geo.place_id があれば）\n",
    "    place_info = {} # 場所情報（geo.place_id があればそのIDに対応する場所情報を取得）を格納する辞書を初期化\n",
    "    geo = tweet.get(\"geo\", {}) # geo 情報を取得（ツイート投稿時に位置情報が付いていれば入っている）\n",
    "    if geo.get(\"place_id\"):\n",
    "        place_info = places_dict.get(geo[\"place_id\"], {}) # geo 内に place_id が存在する場合、そのIDから場所情報を取得\n",
    "\n",
    "    row = {\n",
    "        # ツイート情報\n",
    "        \"text\": tweet.get(\"text\", \"\"), # ツイート本文\n",
    "        #\"text\": tweet.get(\"text\", \"\").replace(\"\\n\", \" \"), # ツイート本文（改行除去）\n",
    "        \"created_at\": tweet[\"created_at\"], # ツイート投稿日時（UTC / 英国時間）\n",
    "        \"created_at_jst\": created_at_jst.strftime(\"%Y-%m-%d %H:%M:%S\") if created_at_jst else \"\", # 日本時間の投稿日時（YYYY-MM-DD HH:MM:SS）\n",
    "        \"tweet_id\": tweet.get(\"id\", \"\"), # ツイート固有のID\n",
    "        \"author_id\": tweet.get(\"author_id\", \"\"), # ツイート投稿者のユーザーID\n",
    "        \"lang\": tweet.get(\"lang\", \"\"), # ツイート言語（例: ja:日本語, en:英語）\n",
    "        \"source\": tweet.get(\"source\", \"\"), # ツイート投稿元アプリ・クライアント名\n",
    "        \"retweet_count\": metrics.get(\"retweet_count\", 0), # リツイート数\n",
    "        \"reply_count\": metrics.get(\"reply_count\", 0), # リプライ数\n",
    "        \"like_count\": metrics.get(\"like_count\", 0), # いいね数\n",
    "        \"quote_count\": metrics.get(\"quote_count\", 0), # 引用ツイート数\n",
    "        \"possibly_sensitive\": tweet.get(\"possibly_sensitive\", False), # センシティブフラグ（Trueならセンシティブ）\n",
    "\n",
    "        # ユーザー情報\n",
    "        \"user_id\": user.get(\"id\", \"\"), # ユーザーID（author_idと同じはず）\n",
    "        \"username\": user.get(\"username\", \"\"), # ユーザーのスクリーンネーム（@名）\n",
    "        \"name\": user.get(\"name\", \"\"), # ユーザーの表示名\n",
    "        \"verified\": user.get(\"verified\", False), # 認証済みアカウントかどうか（True/False）\n",
    "        \"followers_count\": user_metrics.get(\"followers_count\", 0), # フォロワー数\n",
    "        \"following_count\": user_metrics.get(\"following_count\", 0), # フォロー数\n",
    "        \"tweet_count\": user_metrics.get(\"tweet_count\", 0), # トータルツイート数\n",
    "        \"listed_count\": user_metrics.get(\"listed_count\", 0), # リスト登録数\n",
    "        \"user_location\": user.get(\"location\", \"\"), # ユーザーの登録場所情報\n",
    "        \"profile_image_url\": user.get(\"profile_image_url\", \"\"), # プロフィール画像URL\n",
    "        #\"description\": user.get(\"description\", \"\").replace(\"\\n\", \" \"), # プロフィール文\n",
    "        \"description\": user.get(\"description\", \"\").replace(\"\\n\", \" \"), # プロフィール文（改行除去）\n",
    "        \"created_at_user\": user.get(\"created_at\", \"\"), # アカウント作成日時（UTC）\n",
    "        \"url\": user.get(\"url\", \"\"), # ユーザのWebサイトURL\n",
    "        \"pinned_tweet_id\": user.get(\"pinned_tweet_id\", \"\"), # ピン留めツイートのID\n",
    "        \"profile_banner_url\": user.get(\"profile_banner_url\", \"\"), # プロフィールバナー画像URL\n",
    "\n",
    "        # メディア情報（あれば）\n",
    "        \"media_type\": media_info.get(\"type\", \"\"), # メディアタイプ（photo, video, animated_gif など）\n",
    "        \"media_url\": media_info.get(\"url\", \"\"), # メディアのURL（画像・動画）\n",
    "        \"media_preview_image_url\": media_info.get(\"preview_image_url\", \"\"), # 動画のプレビュー画像URL\n",
    "\n",
    "        # 場所情報|ツイートの投稿時に紐づけられた場所情報（あれば.ほとんど空）\n",
    "        \"place_name\": place_info.get(\"name\", \"\"), # 場所の名称（市区町村など）\n",
    "        \"place_country\": place_info.get(\"country\", \"\"), # 国名\n",
    "        \"place_type\": place_info.get(\"place_type\", \"\") # 場所タイプ（city, admin, country など）\n",
    "    }\n",
    "    rows.append(row)# インデント内(for文内に入ってることを確認してください)\n",
    "\n",
    "# =============================\n",
    "# CSVに出力\n",
    "# =============================\n",
    "df = pd.DataFrame(rows) #全てをDataframe化\n",
    "df = df.sort_values(by=\"created_at\")  # created_at の昇順にソート\n",
    "start_str = START_TIME.strftime(\"%Y%m%d_%H%M%S\") #ファイル名にする開始日時(JST)\n",
    "end_str = END_TIME.strftime(\"%Y%m%d_%H%M%S\") #ファイル名にする終了日時(JST)\n",
    "output_path = f\"{OUTPUT_DIRECTORY}/tweets_allinfo_{start_str}_to_{end_str}.csv\" #ファイルパスの指定/ファイル名の指定\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8-sig\") #csv化\n",
    "\n",
    "print(f\"保存しました: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ba9f86",
   "metadata": {},
   "source": [
    "# 分割版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d6415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# =============================\n",
    "# パラメータ設定\n",
    "# =============================\n",
    "\n",
    "# 【毎度いじるパラメータ】~~~~~~~~~~~~\n",
    "START_TIME = datetime(2023, 11, 1, 0, 0, 0) #取得開始日JST（YYYY-MM-DD HH:MM:SS）\n",
    "END_TIME = datetime(2023, 11, 1, 23, 59, 59) #取得終了日JST（YYYY-MM-DD HH:MM:SS）\n",
    "QUERY = \"日経平均 -is:retweet\" #抽出キーワード\n",
    "'''\n",
    "<QUERY = \"日経平均 -is:retweet\"に関して>\n",
    "日経平均：「日経平均」という文字列を含むツイートを検索\n",
    "-is:retweet:かつ、リツイート（RT）は除外する\n",
    "'''\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "MAX_RESULTS = 500 #安田さん500|1リクエストで取得するツイート数の最大値//10以上でないと動かない.\n",
    "MAX_PAGES = 100000 #安田さん100000|最大で何回リクエストを送るかの上限|参照元の安田さんのコードでは、response_count = 10000として定義していた.\n",
    "'''\n",
    "● MAX_RESULTS = 2、MAX_PAGES = 3 の場合\n",
    "ページ1 → 2件取得  \n",
    "ページ2 → 2件取得  \n",
    "ページ3 → 2件取得  \n",
    "== 合計6件取得\n",
    "--------------------------------------------\n",
    "● MAX_RESULTS = 2、MAX_PAGES = 1 の場合\n",
    "ページ1 → 2件取得   \n",
    "== 合計2件取得\n",
    "'''\n",
    "\n",
    "#.envを使うなら(動作保証なし)\n",
    "load_dotenv(\"/home/sakulab/workspace/All_collect_tweet/Forcoltweet/.env\")\n",
    "BEARER_TOKEN = os.getenv('BEARER_TOKEN')\n",
    "\n",
    "#BEARER_TOKEN = 'A'#▲触らない|ベタ打ち\n",
    "OUTPUT_DIRECTORY = \"/home/sakulab/workspace/All_collect_tweet/collected_tweet\" #csv出力先のファイルパス\n",
    "if not BEARER_TOKEN:\n",
    "    print(\"Warning: BEARER_TOKEN is not set in the .env file\")\n",
    "else:\n",
    "    print(\"BEARER_TOKENは正常に取得されました\")\n",
    "\n",
    "# =============================\n",
    "# 時間変換(JST→UTC)\n",
    "# =============================\n",
    "JST = timedelta(hours=9) # 日本標準時 (JST) は UTC +9時間なので、その9時間を引いてUTCに変換するため.\n",
    "start_time_utc = (START_TIME - JST).isoformat() + \"Z\" # 開始日時をUTCに変換し、ISOフォーマット + Z（ゼロ時区）で文字列化\n",
    "end_time_utc = (END_TIME - JST).isoformat() + \"Z\" # 終了日時を同様にUTC変換・フォーマット\n",
    "\n",
    "# =============================\n",
    "# API設定\n",
    "# =============================\n",
    "url = \"https://api.X.com/2/tweets/search/all\" #proプランでの収集用(本家)\n",
    "#url = \"https://api.X.com/2/tweets/search/recent\"#freeプラン収集用(最大10件程度)\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {BEARER_TOKEN}\"} # リクエストヘッダーに Bearer トークンをセット（認証用）\n",
    "\n",
    "#取得要素の設定\n",
    "query_params_base = {\n",
    "    \"query\": QUERY, # 検索クエリ（キーワード＋条件、例：日経平均 -is:retweet）\n",
    "    \"start_time\": start_time_utc, # 検索開始日時（UTC ISO形式）\n",
    "    \"end_time\": end_time_utc, # 検索終了日時（UTC ISO形式）\n",
    "    \"max_results\": MAX_RESULTS, # 1リクエストあたりの最大取得件数（10～500の範囲）\n",
    "    \"tweet.fields\": \",\".join([ # ツイートから取得したいフィールド一覧\n",
    "        \"attachments\", \"author_id\", \"conversation_id\",#\"context_annotations\",\n",
    "        \"created_at\", \"entities\", \"geo\", \"id\", \"in_reply_to_user_id\", \"lang\",\n",
    "        \"public_metrics\", \"possibly_sensitive\", \"referenced_tweets\",\n",
    "        \"reply_settings\", \"source\", \"text\", \"withheld\"\n",
    "    ]),\n",
    "    \"expansions\": \"author_id,attachments.media_keys,referenced_tweets.id\",  # 結果に含める追加データ（例：ユーザー情報・メディア情報）\n",
    "    \"user.fields\": \",\".join([ # ユーザー情報として取得するフィールド\n",
    "        \"created_at\", \"description\", \"entities\", \"id\", \"location\", \"name\",\n",
    "        \"pinned_tweet_id\", \"profile_image_url\", \"protected\", \"public_metrics\",\n",
    "        \"url\", \"username\", \"verified\", \"withheld\"\n",
    "    ]),\n",
    "    \"media.fields\": \"media_key,type,url,preview_image_url,public_metrics\", # メディア情報で取得するフィールド\n",
    "    \"place.fields\": \"full_name,id,country,country_code,geo,name,place_type\" # 場所情報で取得するフィールド\n",
    "} \n",
    "\n",
    "# =============================\n",
    "# データ収集関数\n",
    "# =============================\n",
    "def collect_tweet(url, headers, base_params):\n",
    "    result = [] # すべてのツイートデータを格納するリスト\n",
    "    tweet_count = 0 #実行中のprint用\n",
    "    all_users = {} # ユーザー情報を author_id をキーに格納する辞書\n",
    "    all_media = {} # メディア情報を media_key をキーに格納する辞書\n",
    "    all_places = {} # 場所情報を place_id をキーに格納する辞書\n",
    "    next_token = None # ページング用のトークン（最初はNone）\n",
    "    count = 0 # リクエスト回数のカウンタ\n",
    "\n",
    "    while count < MAX_PAGES: # 最大リクエスト回数に達するまでループ\n",
    "        time.sleep(1) # APIレート制限対策でリクエスト間に1秒の遅延\n",
    "        params = base_params.copy()# base_params（基本のリクエストパラメータ）をコピーして、新しいparamsを作成\n",
    "        if next_token:\n",
    "            params[\"next_token\"] = next_token # 続きを取得する場合は next_token を指定\n",
    "\n",
    "        response = requests.get(url, headers=headers, params=params) # APIリクエスト送信\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Request failed: {response.status_code}, {response.text}\") # エラー時は例外を発生させ、レスポンス内容を表示|例)status-code=404→ページ見つからない\n",
    "\n",
    "        body = response.json() # JSONレスポンスを辞書化\n",
    "        result.extend(body.get(\"data\", [])) # ツイートデータを結果リストに追加\n",
    "\n",
    "        # 累積件数とレート制限の残りを出力\n",
    "        rate_limit = response.headers.get('x-rate-limit-remaining', 'N/A')\n",
    "        tweet_count += len(body.get(\"data\", []))\n",
    "\n",
    "        if body.get(\"data\"):\n",
    "            created_at_jst = datetime.fromisoformat(body[\"data\"][0][\"created_at\"].replace(\"Z\", \"+00:00\")) + JST\n",
    "            print(f\"Rate limit remaining: {rate_limit} | 目安の日付: {created_at_jst} | 累計Tweet_count: {tweet_count}\")\n",
    "        else:\n",
    "            print(f\"Rate limit remaining: {rate_limit} | データなし | 累計Tweet_count: {tweet_count}\")\n",
    "\n",
    "        # 各種インクルードデータ（ユーザー・メディア・場所情報）を辞書に格納\n",
    "        for user in body.get(\"includes\", {}).get(\"users\", []):\n",
    "            all_users[user[\"id\"]] = user\n",
    "        for media in body.get(\"includes\", {}).get(\"media\", []):\n",
    "            all_media[media[\"media_key\"]] = media\n",
    "        for place in body.get(\"includes\", {}).get(\"places\", []):\n",
    "            all_places[place[\"id\"]] = place\n",
    "\n",
    "        count += 1 # リクエスト回数をインクリメント\n",
    "        next_token = body.get(\"meta\", {}).get(\"next_token\")\n",
    "        if not next_token:\n",
    "            print(\"No more pages to fetch.\")\n",
    "            break # 次トークンが無ければこれ以上のデータはないので終了\n",
    "\n",
    "    return result, all_users, all_media, all_places # 収集した全データを返す\n",
    "\n",
    "# =============================\n",
    "# データ収集実行\n",
    "# =============================\n",
    "#tweets, users_dict, media_dict, places_dict = collect_tweet(url, headers, query_params_base)\n",
    "tweets, users_dict, media_dict, places_dict = collect_tweet(\n",
    "    url,                 # APIエンドポイントのURL (search/all)\n",
    "    headers,             # リクエストの認証ヘッダー (Bearerトークン)\n",
    "    query_params_base    # 検索条件・取得フィールドなどを含むパラメータ\n",
    ")\n",
    "'''\n",
    "# collect_tweet 関数を呼び出して、指定の検索条件でデータ収集を実行\n",
    "# 戻り値は以下の4つ:\n",
    "# tweets: ツイートデータ（リスト形式、ツイート1件ずつが辞書）\n",
    "# users_dict: 投稿者ユーザー情報（ユーザーIDをキー、値がユーザー情報の辞書）\n",
    "# media_dict: 添付メディア情報（media_key をキー、値がメディア情報の辞書）\n",
    "# places_dict: 場所情報（place_id をキー、値が場所情報の辞書）\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ecf4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# csv化,データを1行にまとめる\n",
    "# =============================\n",
    "rows = []# rows はツイート＋ユーザー＋メディア＋場所情報を統合したデータを1行ずつ格納するためのリスト.最終的に pandas DataFrame に変換するために使用.\n",
    "\n",
    "for tweet in tqdm(tweets, desc=\"全情報統合中\"):\n",
    "    created_at_jst = (datetime.fromisoformat(tweet[\"created_at\"].replace(\"Z\", \"+00:00\")) + JST) if tweet.get(\"created_at\") else \"\"\n",
    "    # ツイートのcreated_at（UTC:Z=ゼロ時区）をdatetime型に変換し、日本時間 (JST) に変換\n",
    "    # created_at が無ければ空文字\n",
    "\n",
    "    user = users_dict.get(tweet.get(\"author_id\", \"\"), {}) # ツイートの author_id から対応するユーザー情報を取得 / 存在しない場合は空の辞書\n",
    "    user_metrics = user.get(\"public_metrics\", {}) # ユーザーの public_metrics を取得（フォロワー数やツイート数など）/ 無ければ空の辞書\n",
    "    metrics = tweet.get(\"public_metrics\", {}) # ツイートの public_metrics を取得（リツイート数、いいね数など）| 無ければ空の辞書\n",
    "\n",
    "    # メディア情報（複数ある場合は最初のもののみ例として取り出し）\n",
    "    media_info = {} # メディア情報（画像・動画など）を格納する辞書を初期化\n",
    "    media_keys = tweet.get(\"attachments\", {}).get(\"media_keys\", []) # ツイートにメディアが添付されている場合、その media_keys のリストを取得\n",
    "    if media_keys:\n",
    "        media_info = media_dict.get(media_keys[0], {}) # media_keys が存在する場合、最初の media_key に対応するメディア情報を取得\n",
    "\n",
    "    # 場所情報（geo.place_id があれば）\n",
    "    place_info = {} # 場所情報（geo.place_id があればそのIDに対応する場所情報を取得）を格納する辞書を初期化\n",
    "    geo = tweet.get(\"geo\", {}) # geo 情報を取得（ツイート投稿時に位置情報が付いていれば入っている）\n",
    "    if geo.get(\"place_id\"):\n",
    "        place_info = places_dict.get(geo[\"place_id\"], {}) # geo 内に place_id が存在する場合、そのIDから場所情報を取得\n",
    "\n",
    "    row = {\n",
    "        # ツイート情報\n",
    "        \"text\": tweet.get(\"text\", \"\"), # ツイート本文\n",
    "        #\"text\": tweet.get(\"text\", \"\").replace(\"\\n\", \" \"), # ツイート本文（改行除去）\n",
    "        \"created_at\": tweet[\"created_at\"], # ツイート投稿日時（UTC / 英国時間）\n",
    "        \"created_at_jst\": created_at_jst.strftime(\"%Y-%m-%d %H:%M:%S\") if created_at_jst else \"\", # 日本時間の投稿日時（YYYY-MM-DD HH:MM:SS）\n",
    "        \"tweet_id\": tweet.get(\"id\", \"\"), # ツイート固有のID\n",
    "        \"author_id\": tweet.get(\"author_id\", \"\"), # ツイート投稿者のユーザーID\n",
    "        \"lang\": tweet.get(\"lang\", \"\"), # ツイート言語（例: ja:日本語, en:英語）\n",
    "        \"source\": tweet.get(\"source\", \"\"), # ツイート投稿元アプリ・クライアント名\n",
    "        \"retweet_count\": metrics.get(\"retweet_count\", 0), # リツイート数\n",
    "        \"reply_count\": metrics.get(\"reply_count\", 0), # リプライ数\n",
    "        \"like_count\": metrics.get(\"like_count\", 0), # いいね数\n",
    "        \"quote_count\": metrics.get(\"quote_count\", 0), # 引用ツイート数\n",
    "        \"possibly_sensitive\": tweet.get(\"possibly_sensitive\", False), # センシティブフラグ（Trueならセンシティブ）\n",
    "\n",
    "        # ユーザー情報\n",
    "        \"user_id\": user.get(\"id\", \"\"), # ユーザーID（author_idと同じはず）\n",
    "        \"username\": user.get(\"username\", \"\"), # ユーザーのスクリーンネーム（@名）\n",
    "        \"name\": user.get(\"name\", \"\"), # ユーザーの表示名\n",
    "        \"verified\": user.get(\"verified\", False), # 認証済みアカウントかどうか（True/False）\n",
    "        \"followers_count\": user_metrics.get(\"followers_count\", 0), # フォロワー数\n",
    "        \"following_count\": user_metrics.get(\"following_count\", 0), # フォロー数\n",
    "        \"tweet_count\": user_metrics.get(\"tweet_count\", 0), # トータルツイート数\n",
    "        \"listed_count\": user_metrics.get(\"listed_count\", 0), # リスト登録数\n",
    "        \"user_location\": user.get(\"location\", \"\"), # ユーザーの登録場所情報\n",
    "        \"profile_image_url\": user.get(\"profile_image_url\", \"\"), # プロフィール画像URL\n",
    "        #\"description\": user.get(\"description\", \"\").replace(\"\\n\", \" \"), # プロフィール文\n",
    "        \"description\": user.get(\"description\", \"\").replace(\"\\n\", \" \"), # プロフィール文（改行除去）\n",
    "        \"created_at_user\": user.get(\"created_at\", \"\"), # アカウント作成日時（UTC）\n",
    "        \"url\": user.get(\"url\", \"\"), # ユーザのWebサイトURL\n",
    "        \"pinned_tweet_id\": user.get(\"pinned_tweet_id\", \"\"), # ピン留めツイートのID\n",
    "        \"profile_banner_url\": user.get(\"profile_banner_url\", \"\"), # プロフィールバナー画像URL\n",
    "\n",
    "        # メディア情報（あれば）\n",
    "        \"media_type\": media_info.get(\"type\", \"\"), # メディアタイプ（photo, video, animated_gif など）\n",
    "        \"media_url\": media_info.get(\"url\", \"\"), # メディアのURL（画像・動画）\n",
    "        \"media_preview_image_url\": media_info.get(\"preview_image_url\", \"\"), # 動画のプレビュー画像URL\n",
    "\n",
    "        # 場所情報|ツイートの投稿時に紐づけられた場所情報（あれば.ほとんど空）\n",
    "        \"place_name\": place_info.get(\"name\", \"\"), # 場所の名称（市区町村など）\n",
    "        \"place_country\": place_info.get(\"country\", \"\"), # 国名\n",
    "        \"place_type\": place_info.get(\"place_type\", \"\") # 場所タイプ（city, admin, country など）\n",
    "    }\n",
    "    rows.append(row)# インデント内(for文内に入ってることを確認してください)\n",
    "\n",
    "# =============================\n",
    "# CSVに出力\n",
    "# =============================\n",
    "df = pd.DataFrame(rows) #全てをDataframe化\n",
    "df = df.sort_values(by=\"created_at\")  # created_at の昇順にソート\n",
    "start_str = START_TIME.strftime(\"%Y%m%d_%H%M%S\") #ファイル名にする開始日時(JST)\n",
    "end_str = END_TIME.strftime(\"%Y%m%d_%H%M%S\") #ファイル名にする終了日時(JST)\n",
    "output_path = f\"{OUTPUT_DIRECTORY}/tweets_allinfo_{start_str}_to_{end_str}.csv\" #ファイルパスの指定/ファイル名の指定\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8-sig\") #csv化\n",
    "\n",
    "print(f\"保存しました: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
